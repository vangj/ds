{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent, no tears\n",
    "\n",
    "[Gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) is an optimization algorithm to find the minimum of some function. Typically, in machine learning, the function is a [loss function](https://en.wikipedia.org/wiki/Loss_function), which essentially captures the difference between the true and predicted values. Gradient descent has many applications in machine learning and may be applied to (or is the heart and soul of) many machine learning approaches such as find weights for \n",
    "\n",
    "* [regression](https://en.wikipedia.org/wiki/Regression_analysis), \n",
    "* [support vector machines](https://en.wikipedia.org/wiki/Support_vector_machine), and \n",
    "* [deep learning (artificial neural networks)](https://en.wikipedia.org/wiki/Artificial_neural_network).\n",
    "\n",
    "This notebook aims to show the mechanics of gradient descent with no tears (in an easy way)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple linear regression\n",
    "\n",
    "Let's say we have a simple linear regression.\n",
    "\n",
    "$ y = b + wx $\n",
    "\n",
    "where,\n",
    "\n",
    "* $b$ is the y-intercept,\n",
    "* $w$ is the coefficient,\n",
    "* $x$ is the an independent variable value, and\n",
    "* $y$ is the predicted, dependent variable value.\n",
    "\n",
    "Now, we want to estimate $w$. There are many ways to estimate $w$, however, we want to use gradient descent to do so (we will not go into the other ways to estimate $w$). The first thing we have to do is to be able to formulate a loss function. Let's introduce some convenience notation. Assume $\\hat{y}$ is what the model predicts as follows.\n",
    "\n",
    "$ \\hat{y} = f(x) = b + wx $\n",
    "\n",
    "Note that $\\hat{y}$ is just an approximation of the true value $y$. We can define the loss function as follows.\n",
    "\n",
    "$ L(\\hat{y}, y) = (y - \\hat{y})^2 = (y - (b + wx))^2 $\n",
    "\n",
    "The loss function essentially measures the error of the model; the difference in what it predicts $\\hat{y}$ and the true value $y$. Note that we square the difference between $y$ and $\\hat{y}$ as a convenience to get rid of the influence of negative differences. This loss function tells us how much error there is in each of our prediction given our model (the model includes the linear relationship and weight). Since typically we are making several predictions, we want an overall estimation of the error.\n",
    "\n",
    "$ L(\\hat{Y}, Y) = \\frac{1}{N} \\sum{(y - \\hat{y})^2} = \\frac{1}{N} \\sum{(y - (b + wx))^2} $\n",
    "\n",
    "But how does this loss function really guides us to learn or estimate $w$? The best way to understand how the loss function guides us in estimating or learning the weight $w$ is visually. The loss function, in this case, is convex (U-shaped). Notice that the functional form of the loss function is just a squared function not unlike the following.\n",
    "\n",
    "$ y = f(x) = x^2 $\n",
    "\n",
    "If we are asked to find the minimum of such a function, we already know that the lowest point for $y = x^2$ is $y = 0$, and substituting $y = 0$ into the equation, $x = 0$ is the input for which we find the minimum for the function. Another way would be to take the derivative of $f(x)$, $f'(x) = 2x$, and find the value $x$ for which $f'(x) = 0$.\n",
    "\n",
    "However, our situation is slightly different because we need to find $b$ and $w$ to minimize the loss function. The simplest way to find the minimum of the loss function would be to exhaustively iterate through every combination of $b$ and $w$ and see which pair gives us the minimum value. But such approach is computationally expensive. A smart way would be to take the first order partial derivatives of $L$ with respect to $b$ and $w$, and search for values that will minimize simultaneously the partial derivatives.\n",
    "\n",
    "$ \\frac{\\partial L}{\\partial b} = \\frac{2}{N} \\sum{-(y - (b + wx))}$\n",
    "\n",
    "$ \\frac{\\partial L}{\\partial w} = \\frac{2}{N} \\sum{-x (y - (b + wx))}$\n",
    "\n",
    "Remember that the first order derivative gives us the slope of the tanget line to a point on the curve. \n",
    "\n",
    "At this point, the gradient descent algorithm comes into play to help us by using those slopes to move towards the minimum. We already have the training data composed of $N$ pairs of $(y, x)$, but we need to find a pair $b$ and $w$ such that when plugged into the partial derivative functions will minimize the functions. The algorithm for the gradient descent algorithm is as follows.\n",
    "\n",
    "\n",
    "* given \n",
    "  * $(X, Y)$ data of $N$ observations, \n",
    "  * $b$ initial guess, \n",
    "  * $w$ initial guess, and\n",
    "  * $\\alpha$ learning rate\n",
    "* repeat until convergence\n",
    "  * $\\nabla_b = 0$\n",
    "  * $\\nabla_w = 0$\n",
    "  * for each $(x, y)$ in $(X, Y)$\n",
    "    * $\\nabla_b = \\nabla_b - \\frac{2}{N} (y - (b + wx))$\n",
    "    * $\\nabla_w = \\nabla_w - \\frac{2}{N} x (y - (b + wx))$\n",
    "  * $b = b - \\alpha \\nabla_b$\n",
    "  * $w = w - \\alpha \\nabla_w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch gradient descent with to learn parameters of linear equation\n",
    "\n",
    "Batch gradient descent learns the parameters by looking at all the data for each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (100L, 2L)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "np.random.seed(37)\n",
    "num_samples = 100\n",
    "\n",
    "x = 2.0 + np.random.standard_normal(num_samples)\n",
    "y = 5.0 + 2.0 * x + np.random.standard_normal(num_samples)\n",
    "\n",
    "data = np.column_stack((x, y))\n",
    "print('data shape {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xc8ce390>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, y, '.', color='blue', markersize=2.5)\n",
    "plt.plot(x, 5. + 2. * x, '*', color='red', markersize=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_step(data, b, w, alpha=0.005):\n",
    "    b_grad = 0\n",
    "    w_grad = 0\n",
    "    N = data.shape[0]\n",
    "    for i in range(N):\n",
    "        x = data[i][0]\n",
    "        y = data[i][1]\n",
    "        b_grad += -(2./float(N)) * (y - (b + w * x))\n",
    "        w_grad += -(2./float(N)) * x * (y - (b + w * x))\n",
    "    b_new = b - alpha * b_grad\n",
    "    w_new = w - alpha * w_grad\n",
    "    return b_new, w_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: b = 0.182119848515, w = 0.418657084501\n",
      "1000: b = 4.71317690463, w = 2.12235256332\n",
      "2000: b = 4.82183332641, w = 2.07861715642\n",
      "3000: b = 4.82540105864, w = 2.07718110489\n",
      "4000: b = 4.82551820509, w = 2.07713395216\n",
      "5000: b = 4.82552205159, w = 2.0771324039\n",
      "6000: b = 4.82552217789, w = 2.07713235306\n",
      "7000: b = 4.82552218203, w = 2.07713235139\n",
      "8000: b = 4.82552218217, w = 2.07713235134\n",
      "9000: b = 4.82552218217, w = 2.07713235134\n",
      "final: b = 4.82552218217, w = 2.07713235134\n"
     ]
    }
   ],
   "source": [
    "b = 0.\n",
    "w = 0.\n",
    "alpha = 0.01\n",
    "\n",
    "for i in range(10000):\n",
    "    b_new, w_new = batch_step(data, b, w, alpha=alpha)\n",
    "    b = b_new\n",
    "    w = w_new\n",
    "    if i % 1000 == 0:\n",
    "        print('{}: b = {}, w = {}'.format(i, b_new, w_new))\n",
    "        \n",
    "print('final: b = {}, w = {}'.format(b, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xca34a90>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, y, '.', color='blue', markersize=2.5)\n",
    "plt.plot(x, 5. + 2. * x, '*', color='red', markersize=1.5)\n",
    "plt.plot(x, b + w * x, 'v', color='green', markersize=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent with to learn parameters of linear equation\n",
    "\n",
    "Stochastic gradient descent shuffles the data and looks at one data point at a time to learn/update the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_step(x, y, b, w, N, alpha=0.005):\n",
    "    b_grad = -(2./N) * (y - (b + w * x))\n",
    "    w_grad = -(2./N) * x * (y - (b + w * x))\n",
    "    \n",
    "    b_new = b - alpha * b_grad\n",
    "    w_new = w - alpha * w_grad\n",
    "    return b_new, w_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: b = 0.172389256089, w = 0.393491559436\n",
      "1000: b = 4.71266083284, w = 2.12256849052\n",
      "final: b = 4.82164106568, w = 2.07827568777\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "b = 0.\n",
    "w = 0.\n",
    "alpha = 0.01\n",
    "N = float(data.shape[0])\n",
    "\n",
    "for i in range(2000):\n",
    "    indices = list(range(data.shape[0]))\n",
    "    shuffle(indices)\n",
    "    \n",
    "    for j in indices:\n",
    "        b_new, w_new = stochastic_step(data[j][0], data[j][1], b, w, N, alpha=alpha)\n",
    "        b = b_new\n",
    "        w = w_new\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('{}: b = {}, w = {}'.format(i, b_new, w_new))\n",
    "        \n",
    "print('final: b = {}, w = {}'.format(b, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use scikit-learn to learn the parameters of the linear equation\n",
    "\n",
    "As you can see below, the intercept and coefficient are nearly identical to batch and stochastic gradient descent algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.825522182175065\n",
      "[2.07713235]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(fit_intercept=True, normalize=False)\n",
    "lr.fit(data[:, 0].reshape(-1, 1), data[:, 1])\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression\n",
    "\n",
    "This time we apply the gradient descent algorithm to a multiple linear regression problem.\n",
    "\n",
    "$ y = 5.0 + 2.0 x_0 + 1.0 x_1 + 3.0 x_2 + 0.5 x_3 + 1.5 x_4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (100L, 6L)\n"
     ]
    }
   ],
   "source": [
    "x0 = 2.0 + np.random.standard_normal(num_samples)\n",
    "x1 = 1.0 + np.random.standard_normal(num_samples)\n",
    "x2 = -1.0 + np.random.standard_normal(num_samples)\n",
    "x3 = -2.0 + np.random.standard_normal(num_samples)\n",
    "x4 = 0.5 + np.random.standard_normal(num_samples)\n",
    "y = 5.0 + 2.0 * x0 + 1.0 * x1 + 3.0 * x2 + 0.5 * x3 + 1.5 * x4 + np.random.standard_normal(num_samples)\n",
    "\n",
    "data = np.column_stack((x0, x1, x2, x3, x4, y))\n",
    "print('data shape {}'.format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_batch_step(data, b, w, alpha=0.005):\n",
    "    num_x = data.shape[1] - 1\n",
    "    b_grad = 0\n",
    "    w_grad = np.zeros(num_x)\n",
    "    N = data.shape[0]\n",
    "    \n",
    "    for i in range(N):        \n",
    "        y = data[i][num_x]\n",
    "        x = data[i, 0:num_x]\n",
    "        b_grad += -(2./float(N)) * (y - (b + w.dot(x)))\n",
    "        \n",
    "        for j in range(num_x):\n",
    "            x_ij = data[i][j]\n",
    "            w_grad[j] += -(2./float(N)) * x_ij * (y - (b + w.dot(x)))\n",
    "        \n",
    "    b_new = b - alpha * b_grad\n",
    "    w_new = np.array([w[i] - alpha * w_grad[i] for i in range(num_x)])\n",
    "    return b_new, w_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: b = 0.136327978832, w = [ 0.29275746  0.15943176 -0.06731627 -0.2838181   0.1087194 ]\n",
      "1000: b = 3.69074558546, w = [ 2.05046789  0.99662839  2.91470927 -0.01336945  1.51371104]\n",
      "2000: b = 4.51136474575, w = [1.89258252 0.96694568 2.9696926  0.15595645 1.47558119]\n",
      "3000: b = 4.72828192029, w = [1.8508481  0.95909955 2.98422654 0.20071495 1.46550219]\n",
      "4000: b = 4.78562040683, w = [1.83981629 0.95702555 2.98806834 0.21254612 1.46283797]\n",
      "5000: b = 4.80077689246, w = [1.83690022 0.95647732 2.98908386 0.2156735  1.46213373]\n",
      "6000: b = 4.8047832601, w = [1.8361294  0.95633241 2.9893523  0.21650017 1.46194757]\n",
      "7000: b = 4.80584227747, w = [1.83592565 0.9562941  2.98942325 0.21671869 1.46189837]\n",
      "8000: b = 4.80612221129, w = [1.83587179 0.95628398 2.98944201 0.21677645 1.46188536]\n",
      "9000: b = 4.80619620719, w = [1.83585755 0.9562813  2.98944697 0.21679172 1.46188192]\n",
      "final: b = 4.80621575743, w = [1.83585379 0.95628059 2.98944828 0.21679575 1.46188101]\n"
     ]
    }
   ],
   "source": [
    "b = 0.\n",
    "w = np.zeros(data.shape[1] - 1)\n",
    "alpha = 0.01\n",
    "\n",
    "for i in range(10000):\n",
    "    b_new, w_new = multi_batch_step(data, b, w, alpha=alpha)\n",
    "    b = b_new\n",
    "    w = w_new\n",
    "    if i % 1000 == 0:\n",
    "        print('{}: b = {}, w = {}'.format(i, b_new, w_new))\n",
    "        \n",
    "print('final: b = {}, w = {}'.format(b, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.806222794782922\n",
      "[1.83585244 0.95628034 2.98944875 0.2167972  1.46188068]\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=True, normalize=False)\n",
    "lr.fit(data[:, 0:data.shape[1] - 1], data[:, data.shape[1] - 1])\n",
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* [An Introduction to Gradient Descent and Linear Regression](https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/)\n",
    "* [Stochastic Gradient Descent](https://www.youtube.com/watch?v=UfNU3Vhv5CA)\n",
    "* [Rules of calculus - multivariate](http://www.columbia.edu/itc/sipa/math/calc_rules_multivar.html)\n",
    "* [How to overplot a line on a scatter plot in python?](https://stackoverflow.com/questions/19068862/how-to-overplot-a-line-on-a-scatter-plot-in-python)\n",
    "* [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a Look!\n",
    "\n",
    "Take a look at [Dr. Kathryn Laskey](http://seor.vse.gmu.edu/~klaskey/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
